{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c76b170844c1ea2d",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aebc857ccabefdcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T18:49:27.252901Z",
     "start_time": "2024-09-12T18:49:23.590665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-90vnkfq6\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-90vnkfq6\n",
      "\n",
      "  Resolved https://github.com/huggingface/transformers to commit 8bd2b1e8c23234cd607ca8d63f53c1edfea27462\n",
      "  Installing build dependencies ... \u001B[?25ldone\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\n",
      "\u001B[?25hRequirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (3.16.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (0.24.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (2024.9.11)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers==4.45.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers==4.45.0.dev0) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers==4.45.0.dev0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers==4.45.0.dev0) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6d064f254330843",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T18:49:27.805734Z",
     "start_time": "2024-09-12T18:49:27.255147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qwen-vl-utils in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.0.4)\n",
      "Requirement already satisfied: pillow in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from qwen-vl-utils) (10.4.0)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from qwen-vl-utils) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->qwen-vl-utils) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->qwen-vl-utils) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->qwen-vl-utils) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->qwen-vl-utils) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install qwen-vl-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "473b2def78489f75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T18:49:28.327728Z",
     "start_time": "2024-09-12T18:49:27.807217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.17.1+cu121)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.2.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision) (2.2.1+cu121)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (3.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (1.13.2)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.2.1->torchvision) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchvision) (12.6.68)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch==2.2.1->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch==2.2.1->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "541953d9a385e1c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T18:49:28.847097Z",
     "start_time": "2024-09-12T18:49:28.329628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.34.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (2.2.1+cu121)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (0.24.7)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.2)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.6.68)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T10:34:01.617612Z",
     "start_time": "2024-09-16T10:34:01.612914Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from PIL import Image, ImageDraw\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7698a201861b8546",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T10:34:01.955417Z",
     "start_time": "2024-09-16T10:34:01.953195Z"
    }
   },
   "outputs": [],
   "source": [
    "START = time.time()\n",
    "LOCAL_RUN = False\n",
    "\n",
    "if LOCAL_RUN:\n",
    "    IMAGE_PATH = 'images/'\n",
    "    INFERENCE_RESULTS = 'output/inference_results.json'\n",
    "else:\n",
    "    IMAGE_PATH = 'vlm-drones/images/'\n",
    "    INFERENCE_RESULTS = 'vlm-drones/output/inference_results.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f5edf966658b15e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T10:34:02.339314Z",
     "start_time": "2024-09-16T10:34:02.336164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afa65deed77a531",
   "metadata": {},
   "source": [
    "# Aux functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34753affb5213110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box(image_path, bbox):\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    img_width, img_height = image.size\n",
    "\n",
    "    center_x = bbox[0] * img_width\n",
    "    center_y = bbox[1] * img_height\n",
    "    width = bbox[2] * img_width\n",
    "    height = bbox[3] * img_height\n",
    "\n",
    "    top_left_x = int(center_x - (width / 2))\n",
    "    top_left_y = int(center_y - (height / 2))\n",
    "    bottom_right_x = int(center_x + (width / 2))\n",
    "    bottom_right_y = int(center_y + (height / 2))\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.rectangle([top_left_x, top_left_y, bottom_right_x, bottom_right_y], outline=\"red\", width=3)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8e51b358e2bc3a",
   "metadata": {},
   "source": [
    "# Preprocess images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62135c1492138b9c",
   "metadata": {},
   "source": [
    "Check that all images have the same size, in this case 1024X1024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "980fc8a0d5fcbacf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T10:34:03.632959Z",
     "start_time": "2024-09-16T10:34:03.610823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file coordinates.json: cannot identify image file 'images/coordinates.json'\n",
      "Size (1024, 1024) has 403 images: ['img1005997.jpg', 'img1008257.jpg', 'img1008243.jpg', 'img1006285.jpg', 'img1005798.jpg', 'img1009834.jpg', 'img1048459.jpg', 'img1049747.jpg', 'img1008684.jpg', 'img1008451.jpg', 'img1008337.jpg', 'img1005834.jpg', 'img1005809.jpg', 'img1008450.jpg', 'img1006455.jpg', 'img1008685.jpg', 'img1008875.jpg', 'img1006131.jpg', 'img1048464.jpg', 'img1049746.jpg', 'img1048458.jpg', 'img1008281.jpg', 'img1005969.jpg', 'img1005766.jpg', 'img1008242.jpg', 'img1008256.jpg', 'img1006247.jpg', 'img1008268.jpg', 'img1006245.jpg', 'img1008240.jpg', 'img1005764.jpg', 'img1005770.jpg', 'img1008254.jpg', 'img1008283.jpg', 'img1049744.jpg', 'img1006047.jpg', 'img1049750.jpg', 'img1006127.jpg', 'img1008678.jpg', 'img1008888.jpg', 'img1008877.jpg', 'img1008687.jpg', 'img1006457.jpg', 'img1008452.jpg', 'img1008446.jpg', 'img1005837.jpg', 'img1008447.jpg', 'img1008453.jpg', 'img1008309.jpg', 'img1008686.jpg', 'img1008876.jpg', 'img1008889.jpg', 'img1008679.jpg', 'img1006085.jpg', 'img1008725.jpg', 'img1006046.jpg', 'img1049745.jpg', 'img1006052.jpg', 'img1009836.jpg', 'img1008282.jpg', 'img1008255.jpg', 'img1008241.jpg', 'img1005995.jpg', 'img1008269.jpg', 'img1008245.jpg', 'img1005761.jpg', 'img1008251.jpg', 'img1009167.jpg', 'img1005749.jpg', 'img1005991.jpg', 'img1048463.jpg', 'img1008709.jpg', 'img1006081.jpg', 'img1008682.jpg', 'img1008872.jpg', 'img1008866.jpg', 'img1005832.jpg', 'img1006491.jpg', 'img1005827.jpg', 'img1006453.jpg', 'img1008867.jpg', 'img1008873.jpg', 'img1008683.jpg', 'img1008708.jpg', 'img1006043.jpg', 'img1048462.jpg', 'img1006296.jpg', 'img1006241.jpg', 'img1009166.jpg', 'img1005984.jpg', 'img1008250.jpg', 'img1005760.jpg', 'img1008244.jpg', 'img1005776.jpg', 'img1008252.jpg', 'img1008246.jpg', 'img1005762.jpg', 'img1006257.jpg', 'img1008285.jpg', 'img1048460.jpg', 'img1008939.jpg', 'img1008681.jpg', 'img1008454.jpg', 'img1006451.jpg', 'img1007029.jpg', 'img1005830.jpg', 'img1007028.jpg', 'img1008455.jpg', 'img1008870.jpg', 'img1008680.jpg', 'img1006083.jpg', 'img1048461.jpg', 'img1008284.jpg', 'img1006256.jpg', 'img1005763.jpg', 'img1008247.jpg', 'img1008253.jpg', 'img1009670.jpg', 'img1006231.jpg', 'img1005923.jpg', 'img1007463.jpg', 'img1048406.jpg', 'img1008963.jpg', 'img1006635.jpg', 'img1008368.jpg', 'img1008426.jpg', 'img1008340.jpg', 'img1007098.jpg', 'img1009936.jpg', 'img1005671.jpg', 'img1008341.jpg', 'img1008962.jpg', 'img1048407.jpg', 'img1007462.jpg', 'img1005922.jpg', 'img1005739.jpg', 'img1009671.jpg', 'img1009667.jpg', 'img1006226.jpg', 'img1048405.jpg', 'img1008021.jpg', 'img1007460.jpg', 'img1048411.jpg', 'img1008960.jpg', 'img1008419.jpg', 'img1008343.jpg', 'img1005667.jpg', 'img1008425.jpg', 'img1007716.jpg', 'img1005868.jpg', 'img1009935.jpg', 'img1005869.jpg', 'img1005841.jpg', 'img1008342.jpg', 'img1008424.jpg', 'img1005672.jpg', 'img1005882.jpg', 'img1008418.jpg', 'img1007298.jpg', 'img1009504.jpg', 'img1008961.jpg', 'img1007461.jpg', 'img1048410.jpg', 'img1048404.jpg', 'img1005921.jpg', 'img1006227.jpg', 'img1006237.jpg', 'img1008959.jpg', 'img1007288.jpg', 'img1005676.jpg', 'img1008352.jpg', 'img1008420.jpg', 'img1008346.jpg', 'img1005662.jpg', 'img1005892.jpg', 'img1005886.jpg', 'img1005893.jpg', 'img1008421.jpg', 'img1005663.jpg', 'img1008347.jpg', 'img1007289.jpg', 'img1008964.jpg', 'img1008958.jpg', 'img1006020.jpg', 'img1008019.jpg', 'img1006034.jpg', 'img1007464.jpg', 'img1005924.jpg', 'img1006550.jpg', 'img1005729.jpg', 'img1048403.jpg', 'img1006036.jpg', 'img1008345.jpg', 'img1008423.jpg', 'img1008437.jpg', 'img1008351.jpg', 'img1005885.jpg', 'img1005884.jpg', 'img1008350.jpg', 'img1005674.jpg', 'img1008344.jpg', 'img1008422.jpg', 'img1048402.jpg', 'img1007132.jpg', 'img1005916.jpg', 'img1006012.jpg', 'img1008956.jpg', 'img1008942.jpg', 'img1007495.jpg', 'img1006172.jpg', 'img1010076.jpg', 'img1007293.jpg', 'img1007287.jpg', 'img1008349.jpg', 'img1005692.jpg', 'img1005687.jpg', 'img1008348.jpg', 'img1007286.jpg', 'img1007279.jpg', 'img1006615.jpg', 'img1007494.jpg', 'img1008943.jpg', 'img1008957.jpg', 'img1007866.jpg', 'img1005917.jpg', 'img1005724.jpg', 'img1007133.jpg', 'img1005915.jpg', 'img1007864.jpg', 'img1008955.jpg', 'img1007496.jpg', 'img1007284.jpg', 'img1007290.jpg', 'img1008438.jpg', 'img1005691.jpg', 'img1007285.jpg', 'img1006170.jpg', 'img1008954.jpg', 'img1008940.jpg', 'img1006038.jpg', 'img1007859.jpg', 'img1007865.jpg', 'img1009327.jpg', 'img1009333.jpg', 'img1048409.jpg', 'img1007493.jpg', 'img1008950.jpg', 'img1007281.jpg', 'img1007295.jpg', 'img1008415.jpg', 'img1005694.jpg', 'img1007097.jpg', 'img1007096.jpg', 'img1005695.jpg', 'img1008414.jpg', 'img1007294.jpg', 'img1007280.jpg', 'img1006613.jpg', 'img1008951.jpg', 'img1007492.jpg', 'img1048408.jpg', 'img1005905.jpg', 'img1005939.jpg', 'img1009668.jpg', 'img1005907.jpg', 'img1008953.jpg', 'img1007296.jpg', 'img1007282.jpg', 'img1008416.jpg', 'img1005683.jpg', 'img1005867.jpg', 'img1005682.jpg', 'img1005669.jpg', 'img1008417.jpg', 'img1007283.jpg', 'img1007297.jpg', 'img1008952.jpg', 'img1009641.jpg', 'img1009669.jpg', 'img1006273.jpg', 'img1005752.jpg', 'img1008262.jpg', 'img1005975.jpg', 'img1005961.jpg', 'img1006298.jpg', 'img1008712.jpg', 'img1008706.jpg', 'img1006924.jpg', 'img1008869.jpg', 'img1008458.jpg', 'img1007025.jpg', 'img1005829.jpg', 'img1005800.jpg', 'img1007024.jpg', 'img1007030.jpg', 'img1008303.jpg', 'img1009753.jpg', 'img1008459.jpg', 'img1008868.jpg', 'img1008883.jpg', 'img1006925.jpg', 'img1008707.jpg', 'img1008713.jpg', 'img1006058.jpg', 'img1006064.jpg', 'img1007839.jpg', 'img1008263.jpg', 'img1005747.jpg', 'img1007144.jpg', 'img1008249.jpg', 'img1008261.jpg', 'img1005751.jpg', 'img1008705.jpg', 'img1048453.jpg', 'img1008711.jpg', 'img1006927.jpg', 'img1008881.jpg', 'img1007026.jpg', 'img1008301.jpg', 'img1005816.jpg', 'img1005802.jpg', 'img1006489.jpg', 'img1008300.jpg', 'img1008314.jpg', 'img1007027.jpg', 'img1008328.jpg', 'img1006305.jpg', 'img1008880.jpg', 'img1006098.jpg', 'img1006926.jpg', 'img1008710.jpg', 'img1008704.jpg', 'img1005977.jpg', 'img1005963.jpg', 'img1008260.jpg', 'img1008248.jpg', 'img1005778.jpg', 'img1005740.jpg', 'img1008264.jpg', 'img1007143.jpg', 'img1008270.jpg', 'img1008258.jpg', 'img1006275.jpg', 'img1006507.jpg', 'img1005797.jpg', 'img1005967.jpg', 'img1008714.jpg', 'img1048456.jpg', 'img1049748.jpg', 'img1008890.jpg', 'img1007023.jpg', 'img1009754.jpg', 'img1006301.jpg', 'img1008338.jpg', 'img1005813.jpg', 'img1005812.jpg', 'img1008339.jpg', 'img1009755.jpg', 'img1008305.jpg', 'img1008311.jpg', 'img1007022.jpg', 'img1008891.jpg', 'img1006923.jpg', 'img1006062.jpg', 'img1049749.jpg', 'img1048457.jpg', 'img1008701.jpg', 'img1008259.jpg', 'img1008271.jpg', 'img1006248.jpg', 'img1008265.jpg', 'img1008267.jpg', 'img1006510.jpg', 'img1005794.jpg', 'img1008298.jpg', 'img1048455.jpg', 'img1008703.jpg', 'img1006048.jpg', 'img1008677.jpg', 'img1008887.jpg', 'img1008893.jpg', 'img1007020.jpg', 'img1008449.jpg', 'img1005838.jpg', 'img1005804.jpg', 'img1005810.jpg', 'img1005805.jpg', 'img1005839.jpg', 'img1008448.jpg', 'img1007021.jpg', 'img1006459.jpg', 'img1008460.jpg', 'img1008306.jpg', 'img1008892.jpg', 'img1008886.jpg', 'img1008676.jpg', 'img1008702.jpg', 'img1048454.jpg', 'img1008299.jpg', 'img1005965.jpg', 'img1005971.jpg', 'img1005795.jpg', 'img1008266.jpg']\n"
     ]
    }
   ],
   "source": [
    "image_sizes = []\n",
    "\n",
    "for filename in os.listdir(IMAGE_PATH):\n",
    "    filepath = os.path.join(IMAGE_PATH, filename)\n",
    "    if os.path.isfile(filepath):\n",
    "        try:\n",
    "            with Image.open(filepath) as img:\n",
    "                width, height = img.size\n",
    "                image_sizes.append((filename, (width, height)))\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping file {filename}: {e}\")\n",
    "\n",
    "size_to_images = defaultdict(list)\n",
    "\n",
    "for filename, size in image_sizes:\n",
    "    size_to_images[size].append(filename)\n",
    "\n",
    "for size, files in size_to_images.items():\n",
    "    if len(files) > 1:\n",
    "        print(f\"Size {size} has {len(files)} images: {files}\")\n",
    "    else:\n",
    "        print(f\"Size {size} has 1 image: {files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f56b053927af4e",
   "metadata": {},
   "source": [
    "Resize all images to 1024x1024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "861996abb85b930",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:48:21.881410Z",
     "start_time": "2024-09-16T09:48:18.658495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images resized. No bounding box adjustments were necessary since they are in normalized units.\n"
     ]
    }
   ],
   "source": [
    "with open(\"images/coordinates.json\", \"r\") as file:\n",
    "    coordinates = json.load(file)\n",
    "\n",
    "for image_name, bbox in coordinates.items():\n",
    "    \n",
    "    image_path = os.path.join(IMAGE_PATH, image_name)\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    resized_image = image.resize((1024, 1024), Image.Resampling.LANCZOS)\n",
    "    \n",
    "    resized_image_path = os.path.join(IMAGE_PATH, image_name)\n",
    "    resized_image.save(resized_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc99e7d0d5a9ae3b",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8ae08d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9bdb2711c6457691be631338a5dfca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded in 74.54133558273315 seconds\n"
     ]
    }
   ],
   "source": [
    "LOAD_MODEL = time.time()\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-7B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "print(f\"Model loaded in {time.time() - LOAD_MODEL} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a76d7f8f54abceae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor loaded in 0.5134637355804443 seconds\n"
     ]
    }
   ],
   "source": [
    "LOAD_PROCESSOR = time.time()\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\")\n",
    "print(f\"Processor loaded in {time.time() - LOAD_PROCESSOR} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "458c95ebd07d0aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coordinates(output_text):\n",
    "    coord_pattern = r'\\(([\\d\\.\\,\\s]+)\\)'\n",
    "    match = re.search(coord_pattern, output_text)\n",
    "    \n",
    "    if match:\n",
    "\n",
    "        coordinates = match.group(1).split(',')\n",
    "        coordinates = list(map(float, coordinates))\n",
    "        \n",
    "        if len(coordinates) == 4:\n",
    "            return coordinates\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424a60590c592964",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47d6ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(data_directory):\n",
    "    prompt = \"Detect drones in the image. If a drone is detected, return only the bounding box coordinates normalized between 0 and 1, in the format (x, y, w, h), where (x, y) is the top-left corner of the bounding box relative to the image dimensions, and w and h are the width and height relative to the image dimensions. No other text or information; only the coordinates.\"\n",
    "    results_dict = {}\n",
    "    quantity = len(os.listdir(data_directory))\n",
    "\n",
    "    for filename in os.listdir(data_directory):\n",
    "        if filename.endswith('.jpg'):\n",
    "\n",
    "            image_path = os.path.join(data_directory, filename)\n",
    "\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"image\", \"image\": f\"file://{image_path}\"},\n",
    "                        {\"type\": \"text\", \"text\": prompt},\n",
    "                    ],\n",
    "                }\n",
    "            ]\n",
    "\n",
    "            text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "            image_inputs, video_inputs = process_vision_info(messages)\n",
    "            inputs = processor(\n",
    "                text=[text],\n",
    "                images=image_inputs,\n",
    "                videos=video_inputs,\n",
    "                padding=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                generated_ids = model.generate(**inputs, max_new_tokens=64)\n",
    "                generated_ids_trimmed = [\n",
    "                    out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "                ]\n",
    "                output_text = processor.batch_decode(\n",
    "                    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "                )[0]\n",
    "\n",
    "            quantity -= 1\n",
    "            print(f\"Pending to process {quantity}\")\n",
    "            \n",
    "            output_text_parse = extract_coordinates(output_text)\n",
    "\n",
    "            results_dict[filename] = output_text_parse\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(results_dict)\n",
    "    with open(INFERENCE_RESULTS, 'w') as json_file:\n",
    "        json.dump(results_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78d81132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pending to process 403\n",
      "Pending to process 402\n",
      "Pending to process 401\n",
      "Pending to process 400\n",
      "Pending to process 399\n",
      "Pending to process 398\n",
      "Pending to process 397\n",
      "Pending to process 396\n",
      "Pending to process 395\n",
      "Pending to process 394\n",
      "Pending to process 393\n",
      "Pending to process 392\n",
      "Pending to process 391\n",
      "Pending to process 390\n",
      "Pending to process 389\n",
      "Pending to process 388\n",
      "Pending to process 387\n",
      "Pending to process 386\n",
      "Pending to process 385\n",
      "Pending to process 384\n",
      "Pending to process 383\n",
      "Pending to process 382\n",
      "Pending to process 381\n",
      "Pending to process 380\n",
      "Pending to process 379\n",
      "Pending to process 378\n",
      "Pending to process 377\n",
      "Pending to process 376\n",
      "Pending to process 375\n",
      "Pending to process 374\n",
      "Pending to process 373\n",
      "Pending to process 372\n",
      "Pending to process 371\n",
      "Pending to process 370\n",
      "Pending to process 369\n",
      "Pending to process 368\n",
      "Pending to process 367\n",
      "Pending to process 366\n",
      "Pending to process 365\n",
      "Pending to process 364\n",
      "Pending to process 363\n",
      "Pending to process 362\n",
      "Pending to process 361\n",
      "Pending to process 360\n",
      "Pending to process 359\n",
      "Pending to process 358\n",
      "Pending to process 357\n",
      "Pending to process 356\n",
      "Pending to process 355\n",
      "Pending to process 354\n",
      "Pending to process 353\n",
      "Pending to process 352\n",
      "Pending to process 351\n",
      "Pending to process 350\n",
      "Pending to process 349\n",
      "Pending to process 348\n",
      "Pending to process 347\n",
      "Pending to process 346\n",
      "Pending to process 345\n",
      "Pending to process 344\n",
      "Pending to process 343\n",
      "Pending to process 342\n",
      "Pending to process 341\n",
      "Pending to process 340\n",
      "Pending to process 339\n",
      "Pending to process 338\n",
      "Pending to process 337\n",
      "Pending to process 336\n",
      "Pending to process 335\n",
      "Pending to process 334\n",
      "Pending to process 333\n",
      "Pending to process 332\n",
      "Pending to process 331\n",
      "Pending to process 330\n",
      "Pending to process 329\n",
      "Pending to process 328\n",
      "Pending to process 327\n",
      "Pending to process 326\n",
      "Pending to process 325\n",
      "Pending to process 324\n",
      "Pending to process 323\n",
      "Pending to process 322\n",
      "Pending to process 321\n",
      "Pending to process 320\n",
      "Pending to process 319\n",
      "Pending to process 318\n",
      "Pending to process 317\n",
      "Pending to process 316\n",
      "Pending to process 315\n",
      "Pending to process 314\n",
      "Pending to process 313\n",
      "Pending to process 312\n",
      "Pending to process 311\n",
      "Pending to process 310\n",
      "Pending to process 309\n",
      "Pending to process 308\n",
      "Pending to process 307\n",
      "Pending to process 306\n",
      "Pending to process 305\n",
      "Pending to process 304\n",
      "Pending to process 303\n",
      "Pending to process 302\n",
      "Pending to process 301\n",
      "Pending to process 300\n",
      "Pending to process 299\n",
      "Pending to process 298\n",
      "Pending to process 297\n",
      "Pending to process 296\n",
      "Pending to process 295\n",
      "Pending to process 294\n",
      "Pending to process 293\n",
      "Pending to process 292\n",
      "Pending to process 291\n",
      "Pending to process 290\n",
      "Pending to process 289\n",
      "Pending to process 288\n",
      "Pending to process 287\n",
      "Pending to process 286\n",
      "Pending to process 285\n",
      "Pending to process 284\n",
      "Pending to process 283\n",
      "Pending to process 282\n",
      "Pending to process 281\n",
      "Pending to process 280\n",
      "Pending to process 279\n",
      "Pending to process 278\n",
      "Pending to process 277\n",
      "Pending to process 276\n",
      "Pending to process 275\n",
      "Pending to process 274\n",
      "Pending to process 273\n",
      "Pending to process 272\n",
      "Pending to process 271\n",
      "Pending to process 270\n",
      "Pending to process 269\n",
      "Pending to process 268\n",
      "Pending to process 267\n",
      "Pending to process 266\n",
      "Pending to process 265\n",
      "Pending to process 264\n",
      "Pending to process 263\n",
      "Pending to process 262\n",
      "Pending to process 261\n",
      "Pending to process 260\n",
      "Pending to process 259\n",
      "Pending to process 258\n",
      "Pending to process 257\n",
      "Pending to process 256\n",
      "Pending to process 255\n",
      "Pending to process 254\n",
      "Pending to process 253\n",
      "Pending to process 252\n",
      "Pending to process 251\n",
      "Pending to process 250\n",
      "Pending to process 249\n",
      "Pending to process 248\n",
      "Pending to process 247\n",
      "Pending to process 246\n",
      "Pending to process 245\n",
      "Pending to process 244\n",
      "Pending to process 243\n",
      "Pending to process 242\n",
      "Pending to process 241\n",
      "Pending to process 240\n",
      "Pending to process 239\n",
      "Pending to process 238\n",
      "Pending to process 237\n",
      "Pending to process 236\n",
      "Pending to process 235\n",
      "Pending to process 234\n",
      "Pending to process 233\n",
      "Pending to process 232\n",
      "Pending to process 231\n",
      "Pending to process 230\n",
      "Pending to process 229\n",
      "Pending to process 228\n",
      "Pending to process 227\n",
      "Pending to process 226\n",
      "Pending to process 225\n",
      "Pending to process 224\n",
      "Pending to process 223\n",
      "Pending to process 222\n",
      "Pending to process 221\n",
      "Pending to process 220\n",
      "Pending to process 219\n",
      "Pending to process 218\n",
      "Pending to process 217\n",
      "Pending to process 216\n",
      "Pending to process 215\n",
      "Pending to process 214\n",
      "Pending to process 213\n",
      "Pending to process 212\n",
      "Pending to process 211\n",
      "Pending to process 210\n",
      "Pending to process 209\n",
      "Pending to process 208\n",
      "Pending to process 207\n",
      "Pending to process 206\n",
      "Pending to process 205\n",
      "Pending to process 204\n",
      "Pending to process 203\n",
      "Pending to process 202\n",
      "Pending to process 201\n",
      "Pending to process 200\n",
      "Pending to process 199\n",
      "Pending to process 198\n",
      "Pending to process 197\n",
      "Pending to process 196\n",
      "Pending to process 195\n",
      "Pending to process 194\n",
      "Pending to process 193\n",
      "Pending to process 192\n",
      "Pending to process 191\n",
      "Pending to process 190\n",
      "Pending to process 189\n",
      "Pending to process 188\n",
      "Pending to process 187\n",
      "Pending to process 186\n",
      "Pending to process 185\n",
      "Pending to process 184\n",
      "Pending to process 183\n",
      "Pending to process 182\n",
      "Pending to process 181\n",
      "Pending to process 180\n",
      "Pending to process 179\n",
      "Pending to process 178\n",
      "Pending to process 177\n",
      "Pending to process 176\n",
      "Pending to process 175\n",
      "Pending to process 174\n",
      "Pending to process 173\n",
      "Pending to process 172\n",
      "Pending to process 171\n",
      "Pending to process 170\n",
      "Pending to process 169\n",
      "Pending to process 168\n",
      "Pending to process 167\n",
      "Pending to process 166\n",
      "Pending to process 165\n",
      "Pending to process 164\n",
      "Pending to process 163\n",
      "Pending to process 162\n",
      "Pending to process 161\n",
      "Pending to process 160\n",
      "Pending to process 159\n",
      "Pending to process 158\n",
      "Pending to process 157\n",
      "Pending to process 156\n",
      "Pending to process 155\n",
      "Pending to process 154\n",
      "Pending to process 153\n",
      "Pending to process 152\n",
      "Pending to process 151\n",
      "Pending to process 150\n",
      "Pending to process 149\n",
      "Pending to process 148\n",
      "Pending to process 147\n",
      "Pending to process 146\n",
      "Pending to process 145\n",
      "Pending to process 144\n",
      "Pending to process 143\n",
      "Pending to process 142\n",
      "Pending to process 141\n",
      "Pending to process 140\n",
      "Pending to process 139\n",
      "Pending to process 138\n",
      "Pending to process 137\n",
      "Pending to process 136\n",
      "Pending to process 135\n",
      "Pending to process 134\n",
      "Pending to process 133\n",
      "Pending to process 132\n",
      "Pending to process 131\n",
      "Pending to process 130\n",
      "Pending to process 129\n",
      "Pending to process 128\n",
      "Pending to process 127\n",
      "Pending to process 126\n",
      "Pending to process 125\n",
      "Pending to process 124\n",
      "Pending to process 123\n",
      "Pending to process 122\n",
      "Pending to process 121\n",
      "Pending to process 120\n",
      "Pending to process 119\n",
      "Pending to process 118\n",
      "Pending to process 117\n",
      "Pending to process 116\n",
      "Pending to process 115\n",
      "Pending to process 114\n",
      "Pending to process 113\n",
      "Pending to process 112\n",
      "Pending to process 111\n",
      "Pending to process 110\n",
      "Pending to process 109\n",
      "Pending to process 108\n",
      "Pending to process 107\n",
      "Pending to process 106\n",
      "Pending to process 105\n",
      "Pending to process 104\n",
      "Pending to process 103\n",
      "Pending to process 102\n",
      "Pending to process 101\n",
      "Pending to process 100\n",
      "Pending to process 99\n",
      "Pending to process 98\n",
      "Pending to process 97\n",
      "Pending to process 96\n",
      "Pending to process 95\n",
      "Pending to process 94\n",
      "Pending to process 93\n",
      "Pending to process 92\n",
      "Pending to process 91\n",
      "Pending to process 90\n",
      "Pending to process 89\n",
      "Pending to process 88\n",
      "Pending to process 87\n",
      "Pending to process 86\n",
      "Pending to process 85\n",
      "Pending to process 84\n",
      "Pending to process 83\n",
      "Pending to process 82\n",
      "Pending to process 81\n",
      "Pending to process 80\n",
      "Pending to process 79\n",
      "Pending to process 78\n",
      "Pending to process 77\n",
      "Pending to process 76\n",
      "Pending to process 75\n",
      "Pending to process 74\n",
      "Pending to process 73\n",
      "Pending to process 72\n",
      "Pending to process 71\n",
      "Pending to process 70\n",
      "Pending to process 69\n",
      "Pending to process 68\n",
      "Pending to process 67\n",
      "Pending to process 66\n",
      "Pending to process 65\n",
      "Pending to process 64\n",
      "Pending to process 63\n",
      "Pending to process 62\n",
      "Pending to process 61\n",
      "Pending to process 60\n",
      "Pending to process 59\n",
      "Pending to process 58\n",
      "Pending to process 57\n",
      "Pending to process 56\n",
      "Pending to process 55\n",
      "Pending to process 54\n",
      "Pending to process 53\n",
      "Pending to process 52\n",
      "Pending to process 51\n",
      "Pending to process 50\n",
      "Pending to process 49\n",
      "Pending to process 48\n",
      "Pending to process 47\n",
      "Pending to process 46\n",
      "Pending to process 45\n",
      "Pending to process 44\n",
      "Pending to process 43\n",
      "Pending to process 42\n",
      "Pending to process 41\n",
      "Pending to process 40\n",
      "Pending to process 39\n",
      "Pending to process 38\n",
      "Pending to process 37\n",
      "Pending to process 36\n",
      "Pending to process 35\n",
      "Pending to process 34\n",
      "Pending to process 33\n",
      "Pending to process 32\n",
      "Pending to process 31\n",
      "Pending to process 30\n",
      "Pending to process 29\n",
      "Pending to process 28\n",
      "Pending to process 27\n",
      "Pending to process 26\n",
      "Pending to process 25\n",
      "Pending to process 24\n",
      "Pending to process 23\n",
      "Pending to process 22\n",
      "Pending to process 21\n",
      "Pending to process 20\n",
      "Pending to process 19\n",
      "Pending to process 18\n",
      "Pending to process 17\n",
      "Pending to process 16\n",
      "Pending to process 15\n",
      "Pending to process 14\n",
      "Pending to process 13\n",
      "Pending to process 12\n",
      "Pending to process 11\n",
      "Pending to process 10\n",
      "Pending to process 9\n",
      "Pending to process 8\n",
      "Pending to process 7\n",
      "Pending to process 6\n",
      "Pending to process 5\n",
      "Pending to process 4\n",
      "Pending to process 3\n",
      "Pending to process 2\n",
      "Pending to process 1\n",
      "{'img1005662.jpg': {'Inference': [0.25, 0.42, 0.33, 0.48]}, 'img1005663.jpg': {'Inference': [0.71, 0.18, 0.79, 0.23]}, 'img1005667.jpg': {'Inference': [0.01, 0.34, 0.06, 0.4]}, 'img1005669.jpg': {'Inference': [0.04, 0.25, 0.12, 0.31]}, 'img1005671.jpg': {'Inference': [0.11, 0.27, 0.2, 0.33]}, 'img1005672.jpg': {'Inference': [0.23, 0.54, 0.31, 0.6]}, 'img1005674.jpg': {'Inference': [0.64, 0.43, 0.71, 0.48]}, 'img1005676.jpg': {'Inference': [0.69, 0.44, 0.76, 0.49]}, 'img1005682.jpg': {'Inference': [0.66, 0.38, 0.73, 0.42]}, 'img1005683.jpg': {'Inference': [0.96, 0.31, 1.0, 0.35]}, 'img1005687.jpg': {'Inference': [0.03, 0.58, 0.09, 0.63]}, 'img1005691.jpg': {'Inference': [0.73, 0.24, 0.79, 0.28]}, 'img1005692.jpg': {'Inference': [0.56, 0.19, 0.64, 0.24]}, 'img1005694.jpg': {'Inference': [0.25, 0.42, 0.37, 0.51]}, 'img1005695.jpg': {'Inference': [0.69, 0.18, 0.81, 0.25]}, 'img1005724.jpg': {'Inference': [0.53, 0.37, 0.61, 0.43]}, 'img1005729.jpg': {'Inference': [0.21, 0.46, 0.33, 0.53]}, 'img1005739.jpg': {'Inference': [0.32, 0.33, 0.46, 0.43]}, 'img1005740.jpg': {'Inference': [0.59, 0.54, 0.69, 0.6]}, 'img1005747.jpg': {'Inference': [0.59, 0.48, 0.66, 0.52]}, 'img1005749.jpg': {'Inference': [0.53, 0.4, 0.58, 0.43]}, 'img1005751.jpg': {'Inference': [0.58, 0.27, 0.69, 0.35]}, 'img1005752.jpg': {'Inference': [0.64, 0.65, 0.75, 0.71]}, 'img1005760.jpg': {'Inference': [0.42, 0.19, 0.49, 0.23]}, 'img1005761.jpg': {'Inference': [0.35, 0.28, 0.45, 0.34]}, 'img1005762.jpg': {'Inference': [328.0, 150.0, 396.0, 166.0]}, 'img1005763.jpg': {'Inference': [0.39, 0.39, 0.48, 0.46]}, 'img1005764.jpg': {'Inference': [0.31, 0.13, 0.44, 0.21]}, 'img1005766.jpg': {'Inference': [0.4, 0.2, 0.54, 0.3]}, 'img1005770.jpg': {'Inference': [0.13, 0.48, 0.22, 0.55]}, 'img1005776.jpg': {'Inference': [0.22, 0.25, 0.34, 0.32]}, 'img1005778.jpg': {'Inference': [0.12, 0.49, 0.2, 0.55]}, 'img1005794.jpg': {'Inference': [540.0, 398.0, 609.0, 453.0]}, 'img1005795.jpg': {'Inference': [570.0, 600.0, 635.0, 650.0]}, 'img1005797.jpg': {'Inference': [250.0, 425.0, 325.0, 480.0]}, 'img1005798.jpg': {'Inference': [0.29, 0.63, 0.35, 0.68]}, 'img1005800.jpg': {'Inference': [178.0, 154.0, 248.0, 214.0]}, 'img1005802.jpg': {'Inference': [0.43, 0.61, 0.5, 0.65]}, 'img1005804.jpg': {'Inference': [0.58, 0.42, 0.65, 0.47]}, 'img1005805.jpg': {'Inference': [586.0, 255.0, 650.0, 310.0]}, 'img1005809.jpg': {'Inference': [628.0, 166.0, 768.0, 269.0]}, 'img1005810.jpg': {'Inference': [0.56, 0.42, 0.63, 0.48]}, 'img1005812.jpg': {'Inference': [515.0, 392.0, 584.0, 447.0]}, 'img1005813.jpg': {'Inference': [720.0, 848.0, 798.0, 898.0]}, 'img1005816.jpg': {'Inference': [0.79, 0.64, 0.91, 0.74]}, 'img1005827.jpg': {'Inference': [0.32, 0.5, 0.37, 0.54]}, 'img1005829.jpg': {'Inference': [0.45, 0.4, 0.5, 0.43]}, 'img1005830.jpg': {'Inference': [0.37, 0.64, 0.4, 0.66]}, 'img1005832.jpg': {'Inference': [0.45, 0.66, 0.48, 0.69]}, 'img1005834.jpg': {'Inference': [0.89, 0.46, 0.95, 0.5]}, 'img1005837.jpg': {'Inference': [0.62, 0.5, 0.67, 0.54]}, 'img1005838.jpg': {'Inference': [0.57, 0.61, 0.6, 0.64]}, 'img1005839.jpg': {'Inference': [0.35, 0.43, 0.38, 0.45]}, 'img1005841.jpg': {'Inference': [0.45, 0.43, 0.49, 0.46]}, 'img1005867.jpg': {'Inference': [0.31, 0.44, 0.35, 0.47]}, 'img1005868.jpg': {'Inference': [0.4, 0.34, 0.45, 0.38]}, 'img1005869.jpg': {'Inference': [0.79, 0.28, 0.83, 0.31]}, 'img1005882.jpg': {'Inference': 0}, 'img1005884.jpg': {'Inference': 0}, 'img1005885.jpg': {'Inference': 0}, 'img1005886.jpg': {'Inference': 0}, 'img1005892.jpg': {'Inference': 0}, 'img1005893.jpg': {'Inference': 0}, 'img1005905.jpg': {'Inference': 0}, 'img1005907.jpg': {'Inference': 0}, 'img1005915.jpg': {'Inference': [0.42, 0.34, 0.45, 0.36]}, 'img1005916.jpg': {'Inference': 0}, 'img1005917.jpg': {'Inference': 0}, 'img1005921.jpg': {'Inference': 0}, 'img1005922.jpg': {'Inference': 0}, 'img1005923.jpg': {'Inference': 0}, 'img1005924.jpg': {'Inference': 0}, 'img1005939.jpg': {'Inference': 0}, 'img1005961.jpg': {'Inference': 0}, 'img1005963.jpg': {'Inference': [0.67, 0.47, 0.7, 0.5]}, 'img1005965.jpg': {'Inference': 0}, 'img1005967.jpg': {'Inference': [0.79, 0.48, 0.83, 0.51]}, 'img1005969.jpg': {'Inference': [0.78, 0.44, 0.82, 0.47]}, 'img1005971.jpg': {'Inference': 0}, 'img1005975.jpg': {'Inference': 0}, 'img1005977.jpg': {'Inference': 0}, 'img1005984.jpg': {'Inference': 0}, 'img1005991.jpg': {'Inference': [0.46, 0.66, 0.51, 0.8]}, 'img1005995.jpg': {'Inference': [0.44, 0.63, 0.48, 0.67]}, 'img1005997.jpg': {'Inference': [0.5, 0.65, 0.52, 0.7]}, 'img1006012.jpg': {'Inference': 0}, 'img1006020.jpg': {'Inference': 0}, 'img1006034.jpg': {'Inference': [0.54, 0.83, 0.58, 0.86]}, 'img1006036.jpg': {'Inference': [0.43, 0.79, 0.47, 0.82]}, 'img1006038.jpg': {'Inference': 0}, 'img1006043.jpg': {'Inference': 0}, 'img1006046.jpg': {'Inference': [0.59, 0.55, 0.65, 0.59]}, 'img1006047.jpg': {'Inference': 0}, 'img1006048.jpg': {'Inference': [465.0, 662.0, 500.0, 692.0]}, 'img1006052.jpg': {'Inference': 0}, 'img1006058.jpg': {'Inference': [0.4, 0.48, 0.44, 0.51]}, 'img1006062.jpg': {'Inference': [0.5, 0.55, 0.54, 0.58]}, 'img1006064.jpg': {'Inference': [0.48, 0.57, 0.53, 0.62]}, 'img1006081.jpg': {'Inference': 0}, 'img1006083.jpg': {'Inference': 0}, 'img1006085.jpg': {'Inference': 0}, 'img1006098.jpg': {'Inference': 0}, 'img1006127.jpg': {'Inference': 0}, 'img1006131.jpg': {'Inference': 0}, 'img1006170.jpg': {'Inference': [185.0, 366.0, 270.0, 430.0]}, 'img1006172.jpg': {'Inference': [0.3, 0.51, 0.37, 0.56]}, 'img1006226.jpg': {'Inference': [0.49, 0.5, 0.51, 0.52]}, 'img1006227.jpg': {'Inference': [0.42, 0.55, 0.47, 0.58]}, 'img1006231.jpg': {'Inference': 0}, 'img1006237.jpg': {'Inference': 0}, 'img1006241.jpg': {'Inference': 0}, 'img1006245.jpg': {'Inference': 0}, 'img1006247.jpg': {'Inference': 0}, 'img1006248.jpg': {'Inference': 0}, 'img1006256.jpg': {'Inference': [0.89, 0.4, 0.93, 0.43]}, 'img1006257.jpg': {'Inference': [0.73, 0.26, 0.78, 0.31]}, 'img1006273.jpg': {'Inference': [0.78, 0.36, 0.87, 0.42]}, 'img1006275.jpg': {'Inference': [0.63, 0.37, 0.73, 0.43]}, 'img1006285.jpg': {'Inference': [0.8, 0.57, 0.85, 0.62]}, 'img1006296.jpg': {'Inference': [0.59, 0.57, 0.62, 0.6]}, 'img1006298.jpg': {'Inference': [578.0, 591.0, 628.0, 635.0]}, 'img1006301.jpg': {'Inference': [720.0, 700.0, 770.0, 740.0]}, 'img1006305.jpg': {'Inference': [0.2, 0.59, 0.27, 0.64]}, 'img1006451.jpg': {'Inference': [0.47, 0.43, 0.53, 0.47]}, 'img1006453.jpg': {'Inference': [0.14, 0.59, 0.2, 0.63]}, 'img1006455.jpg': {'Inference': [0.45, 0.79, 0.5, 0.82]}, 'img1006457.jpg': {'Inference': [0.64, 0.85, 0.72, 0.89]}, 'img1006459.jpg': {'Inference': [548.0, 888.0, 640.0, 968.0]}, 'img1006489.jpg': {'Inference': [605.0, 600.0, 655.0, 637.0]}, 'img1006491.jpg': {'Inference': [0.32, 0.42, 0.41, 0.47]}, 'img1006507.jpg': {'Inference': [0.92, 0.73, 0.96, 0.77]}, 'img1006510.jpg': {'Inference': [0.62, 0.47, 0.66, 0.5]}, 'img1006550.jpg': {'Inference': [550.0, 728.0, 575.0, 753.0]}, 'img1006613.jpg': {'Inference': [0.13, 0.28, 0.19, 0.32]}, 'img1006615.jpg': {'Inference': [0.78, 0.31, 0.84, 0.35]}, 'img1006635.jpg': {'Inference': [0.5, 0.36, 0.54, 0.4]}, 'img1006923.jpg': {'Inference': [0.12, 0.47, 0.16, 0.5]}, 'img1006924.jpg': {'Inference': [0.68, 0.48, 0.7, 0.5]}, 'img1006925.jpg': {'Inference': 0}, 'img1006926.jpg': {'Inference': 0}, 'img1006927.jpg': {'Inference': [0.16, 0.55, 0.19, 0.57]}, 'img1007020.jpg': {'Inference': [0.31, 0.46, 0.34, 0.48]}, 'img1007021.jpg': {'Inference': 0}, 'img1007022.jpg': {'Inference': [0.27, 0.39, 0.31, 0.42]}, 'img1007023.jpg': {'Inference': [0.31, 0.38, 0.34, 0.41]}, 'img1007024.jpg': {'Inference': [0.46, 0.49, 0.49, 0.51]}, 'img1007025.jpg': {'Inference': [0.43, 0.51, 0.46, 0.54]}, 'img1007026.jpg': {'Inference': [0.59, 0.48, 0.64, 0.51]}, 'img1007027.jpg': {'Inference': 0}, 'img1007028.jpg': {'Inference': 0}, 'img1007029.jpg': {'Inference': [0.41, 0.39, 0.44, 0.41]}, 'img1007030.jpg': {'Inference': [0.66, 0.39, 0.69, 0.42]}, 'img1007096.jpg': {'Inference': [0.91, 0.48, 0.94, 0.51]}, 'img1007097.jpg': {'Inference': [0.62, 0.48, 0.65, 0.51]}, 'img1007098.jpg': {'Inference': [0.38, 0.59, 0.41, 0.62]}, 'img1007132.jpg': {'Inference': [0.77, 0.53, 0.8, 0.56]}, 'img1007133.jpg': {'Inference': [0.56, 0.3, 0.6, 0.33]}, 'img1007143.jpg': {'Inference': [0.68, 0.43, 0.71, 0.46]}, 'img1007144.jpg': {'Inference': [0.43, 0.51, 0.45, 0.53]}, 'img1007279.jpg': {'Inference': [0.66, 0.44, 0.69, 0.47]}, 'img1007280.jpg': {'Inference': [0.29, 0.48, 0.32, 0.51]}, 'img1007281.jpg': {'Inference': [0.39, 0.31, 0.43, 0.35]}, 'img1007282.jpg': {'Inference': [0.65, 0.55, 0.7, 0.59]}, 'img1007283.jpg': {'Inference': [0.82, 0.67, 0.88, 0.71]}, 'img1007284.jpg': {'Inference': [0.53, 0.49, 0.6, 0.54]}, 'img1007285.jpg': {'Inference': 0}, 'img1007286.jpg': {'Inference': [0.62, 0.73, 0.68, 0.77]}, 'img1007287.jpg': {'Inference': [745.0, 404.0, 799.0, 448.0]}, 'img1007288.jpg': {'Inference': [0.09, 0.44, 0.14, 0.48]}, 'img1007289.jpg': {'Inference': [0.22, 0.13, 0.27, 0.18]}, 'img1007290.jpg': {'Inference': [666.67, 0.33, 0.7, 0.36]}, 'img1007293.jpg': {'Inference': [0.6, 0.42, 0.65, 0.46]}, 'img1007294.jpg': {'Inference': [0.59, 0.38, 0.63, 0.41]}, 'img1007295.jpg': {'Inference': [0.54, 0.31, 0.58, 0.34]}, 'img1007296.jpg': {'Inference': [0.66, 0.28, 0.7, 0.31]}, 'img1007297.jpg': {'Inference': [628.0, 296.0, 662.0, 330.0]}, 'img1007298.jpg': {'Inference': [0.6, 0.35, 0.64, 0.38]}, 'img1007460.jpg': {'Inference': [0.82, 0.43, 0.86, 0.46]}, 'img1007461.jpg': {'Inference': [0.89, 0.4, 0.93, 0.43]}, 'img1007462.jpg': {'Inference': [0.42, 0.62, 0.45, 0.66]}, 'img1007463.jpg': {'Inference': [0.76, 0.53, 0.79, 0.56]}, 'img1007464.jpg': {'Inference': [0.21, 0.43, 0.24, 0.46]}, 'img1007492.jpg': {'Inference': [0.38, 0.21, 0.41, 0.23]}, 'img1007493.jpg': {'Inference': [0.44, 0.28, 0.48, 0.31]}, 'img1007494.jpg': {'Inference': [0.4, 0.3, 0.43, 0.33]}, 'img1007495.jpg': {'Inference': [0.4, 0.4, 0.43, 0.43]}, 'img1007496.jpg': {'Inference': [0.47, 0.42, 0.5, 0.44]}, 'img1007716.jpg': {'Inference': [0.36, 0.51, 0.41, 0.55]}, 'img1007839.jpg': {'Inference': [0.37, 0.61, 0.41, 0.65]}, 'img1007859.jpg': {'Inference': [0.2, 0.57, 0.23, 0.6]}, 'img1007864.jpg': {'Inference': [0.34, 0.54, 0.38, 0.58]}, 'img1007865.jpg': {'Inference': [0.15, 0.46, 0.18, 0.5]}, 'img1007866.jpg': {'Inference': [0.31, 0.68, 0.33, 0.7]}, 'img1008019.jpg': {'Inference': [0.47, 0.63, 0.5, 0.66]}, 'img1008021.jpg': {'Inference': [0.62, 0.58, 0.65, 0.61]}, 'img1008240.jpg': {'Inference': [0.23, 0.32, 0.26, 0.35]}, 'img1008241.jpg': {'Inference': [0.02, 0.27, 0.05, 0.3]}, 'img1008242.jpg': {'Inference': [0.43, 0.08, 0.46, 0.11]}, 'img1008243.jpg': {'Inference': [618.0, 188.0, 648.0, 225.0]}, 'img1008244.jpg': {'Inference': [671.0, 114.0, 704.0, 155.0]}, 'img1008245.jpg': {'Inference': [0.79, 0.12, 0.83, 0.16]}, 'img1008246.jpg': {'Inference': [0.02, 0.01, 0.05, 0.05]}, 'img1008247.jpg': {'Inference': [0.03, 0.1, 0.06, 0.13]}, 'img1008248.jpg': {'Inference': 0}, 'img1008249.jpg': {'Inference': [0.3, 0.37, 0.33, 0.4]}, 'img1008250.jpg': {'Inference': [0.53, 0.35, 0.55, 0.37]}, 'img1008251.jpg': {'Inference': 0}, 'img1008252.jpg': {'Inference': [0.64, 0.28, 0.67, 0.31]}, 'img1008253.jpg': {'Inference': [0.31, 0.33, 0.34, 0.36]}, 'img1008254.jpg': {'Inference': [0.21, 0.27, 0.24, 0.3]}, 'img1008255.jpg': {'Inference': [0.17, 0.27, 0.2, 0.3]}, 'img1008256.jpg': {'Inference': [0.3, 0.36, 0.33, 0.39]}, 'img1008257.jpg': {'Inference': 0}, 'img1008258.jpg': {'Inference': 0}, 'img1008259.jpg': {'Inference': 0}, 'img1008260.jpg': {'Inference': [0.51, 0.56, 0.54, 0.6]}, 'img1008261.jpg': {'Inference': [0.37, 0.53, 0.4, 0.56]}, 'img1008262.jpg': {'Inference': [0.33, 0.66, 0.36, 0.69]}, 'img1008263.jpg': {'Inference': [656.0, 628.0, 679.0, 654.0]}, 'img1008264.jpg': {'Inference': [0.48, 0.58, 0.51, 0.62]}, 'img1008265.jpg': {'Inference': [0.58, 0.52, 0.61, 0.55]}, 'img1008266.jpg': {'Inference': [0.7, 0.5, 0.74, 0.54]}, 'img1008267.jpg': {'Inference': [0.48, 0.56, 0.51, 0.6]}, 'img1008268.jpg': {'Inference': [0.7, 0.51, 0.73, 0.55]}, 'img1008269.jpg': {'Inference': 0}, 'img1008270.jpg': {'Inference': [0.45, 0.57, 0.47, 0.6]}, 'img1008271.jpg': {'Inference': [0.27, 0.47, 0.31, 0.52]}, 'img1008281.jpg': {'Inference': [0.09, 0.53, 0.12, 0.56]}, 'img1008282.jpg': {'Inference': [0.39, 0.67, 0.42, 0.7]}, 'img1008283.jpg': {'Inference': [573.0, 722.0, 596.0, 752.0]}, 'img1008284.jpg': {'Inference': 0}, 'img1008285.jpg': {'Inference': 0}, 'img1008298.jpg': {'Inference': [0.43, 0.31, 0.47, 0.35]}, 'img1008299.jpg': {'Inference': [0.78, 0.28, 0.81, 0.31]}, 'img1008300.jpg': {'Inference': [0.64, 0.46, 0.67, 0.5]}, 'img1008301.jpg': {'Inference': [0.64, 0.63, 0.68, 0.67]}, 'img1008303.jpg': {'Inference': [0.73, 0.69, 0.77, 0.73]}, 'img1008305.jpg': {'Inference': [0.28, 0.39, 0.31, 0.42]}, 'img1008306.jpg': {'Inference': 0}, 'img1008309.jpg': {'Inference': [0.44, 0.46, 0.47, 0.5]}, 'img1008311.jpg': {'Inference': [0.3, 0.5, 0.33, 0.53]}, 'img1008314.jpg': {'Inference': 0}, 'img1008328.jpg': {'Inference': [0.42, 0.58, 0.45, 0.61]}, 'img1008337.jpg': {'Inference': [0.07, 0.26, 0.13, 0.31]}, 'img1008338.jpg': {'Inference': [0.14, 0.48, 0.17, 0.51]}, 'img1008339.jpg': {'Inference': [0.4, 0.52, 0.42, 0.55]}, 'img1008340.jpg': {'Inference': [0.89, 0.18, 0.91, 0.2]}, 'img1008341.jpg': {'Inference': 0}, 'img1008342.jpg': {'Inference': [0.61, 0.29, 0.64, 0.32]}, 'img1008343.jpg': {'Inference': [0.84, 0.27, 0.86, 0.29]}, 'img1008344.jpg': {'Inference': [0.33, 0.35, 0.36, 0.37]}, 'img1008345.jpg': {'Inference': [0.37, 0.37, 0.4, 0.4]}, 'img1008346.jpg': {'Inference': [0.84, 0.3, 0.87, 0.33]}, 'img1008347.jpg': {'Inference': [0.5, 0.34, 0.53, 0.37]}, 'img1008348.jpg': {'Inference': 0}, 'img1008349.jpg': {'Inference': 0}, 'img1008350.jpg': {'Inference': 0}, 'img1008351.jpg': {'Inference': 0}, 'img1008352.jpg': {'Inference': [0.46, 0.33, 0.48, 0.35]}, 'img1008368.jpg': {'Inference': [0.81, 0.53, 0.84, 0.56]}, 'img1008414.jpg': {'Inference': [0.38, 0.55, 0.42, 0.59]}, 'img1008415.jpg': {'Inference': [0.4, 0.48, 0.44, 0.53]}, 'img1008416.jpg': {'Inference': [0.43, 0.57, 0.45, 0.61]}, 'img1008417.jpg': {'Inference': [0.34, 0.62, 0.38, 0.65]}, 'img1008418.jpg': {'Inference': [525.0, 583.0, 542.0, 605.0]}, 'img1008419.jpg': {'Inference': [550.0, 650.0, 570.0, 675.0]}, 'img1008420.jpg': {'Inference': [548.0, 658.0, 565.0, 680.0]}, 'img1008421.jpg': {'Inference': [539.0, 648.0, 556.0, 674.0]}, 'img1008422.jpg': {'Inference': [0.36, 0.57, 0.39, 0.6]}, 'img1008423.jpg': {'Inference': [0.25, 0.6, 0.29, 0.64]}, 'img1008424.jpg': {'Inference': [0.4, 0.63, 0.44, 0.68]}, 'img1008425.jpg': {'Inference': [0.86, 0.41, 0.89, 0.44]}, 'img1008426.jpg': {'Inference': [550.0, 625.0, 568.0, 651.0]}, 'img1008437.jpg': {'Inference': [0.21, 0.62, 0.24, 0.65]}, 'img1008438.jpg': {'Inference': [0.21, 0.65, 0.25, 0.69]}, 'img1008446.jpg': {'Inference': [0.74, 0.39, 0.77, 0.42]}, 'img1008447.jpg': {'Inference': [0.79, 0.45, 0.84, 0.49]}, 'img1008448.jpg': {'Inference': [0.86, 0.5, 0.89, 0.53]}, 'img1008449.jpg': {'Inference': [0.84, 0.51, 0.86, 0.53]}, 'img1008450.jpg': {'Inference': [0.83, 0.52, 0.86, 0.55]}, 'img1008451.jpg': {'Inference': [0.84, 0.54, 0.86, 0.56]}, 'img1008452.jpg': {'Inference': [0.91, 0.57, 0.94, 0.6]}, 'img1008453.jpg': {'Inference': [0.69, 0.58, 0.73, 0.62]}, 'img1008454.jpg': {'Inference': [0.29, 0.55, 0.32, 0.59]}, 'img1008455.jpg': {'Inference': [0.1, 0.65, 0.14, 0.69]}, 'img1008458.jpg': {'Inference': [0.11, 0.5, 0.16, 0.54]}, 'img1008459.jpg': {'Inference': [0.25, 0.63, 0.29, 0.67]}, 'img1008460.jpg': {'Inference': [0.34, 0.66, 0.38, 0.7]}, 'img1008676.jpg': {'Inference': [0.44, 0.39, 0.46, 0.41]}, 'img1008677.jpg': {'Inference': [0.46, 0.35, 0.49, 0.38]}, 'img1008678.jpg': {'Inference': [0.5, 0.5, 0.52, 0.52]}, 'img1008679.jpg': {'Inference': [726.0, 258.0, 753.0, 295.0]}, 'img1008680.jpg': {'Inference': 0}, 'img1008681.jpg': {'Inference': [0.59, 0.5, 0.62, 0.53]}, 'img1008682.jpg': {'Inference': [0.5, 0.5, 0.52, 0.53]}, 'img1008683.jpg': {'Inference': [0.37, 0.43, 0.41, 0.47]}, 'img1008684.jpg': {'Inference': [0.48, 0.51, 0.5, 0.54]}, 'img1008685.jpg': {'Inference': [0.64, 0.37, 0.67, 0.4]}, 'img1008686.jpg': {'Inference': [0.24, 0.49, 0.27, 0.52]}, 'img1008687.jpg': {'Inference': 0}, 'img1008701.jpg': {'Inference': [0.61, 0.52, 0.64, 0.55]}, 'img1008702.jpg': {'Inference': 0}, 'img1008703.jpg': {'Inference': [0.62, 0.36, 0.65, 0.39]}, 'img1008704.jpg': {'Inference': [0.48, 0.4, 0.5, 0.43]}, 'img1008705.jpg': {'Inference': [733.0, 289.0, 758.0, 319.0]}, 'img1008706.jpg': {'Inference': [0.68, 0.32, 0.71, 0.35]}, 'img1008707.jpg': {'Inference': [0.93, 0.29, 0.97, 0.32]}, 'img1008708.jpg': {'Inference': [0.92, 0.31, 0.95, 0.33]}, 'img1008709.jpg': {'Inference': [0.92, 0.31, 0.95, 0.33]}, 'img1008710.jpg': {'Inference': [0.79, 0.4, 0.83, 0.43]}, 'img1008711.jpg': {'Inference': 0}, 'img1008712.jpg': {'Inference': [0.58, 0.28, 0.62, 0.32]}, 'img1008713.jpg': {'Inference': [0.89, 0.36, 0.92, 0.39]}, 'img1008714.jpg': {'Inference': 0}, 'img1008725.jpg': {'Inference': [0.22, 0.55, 0.26, 0.59]}, 'img1008866.jpg': {'Inference': [0.63, 0.33, 0.67, 0.36]}, 'img1008867.jpg': {'Inference': [0.45, 0.2, 0.5, 0.24]}, 'img1008868.jpg': {'Inference': [0.27, 0.24, 0.31, 0.28]}, 'img1008869.jpg': {'Inference': [0.11, 0.23, 0.17, 0.28]}, 'img1008870.jpg': {'Inference': [0.3, 0.23, 0.35, 0.27]}, 'img1008872.jpg': {'Inference': [0.48, 0.17, 0.51, 0.2]}, 'img1008873.jpg': {'Inference': [0.24, 0.08, 0.29, 0.13]}, 'img1008875.jpg': {'Inference': [0.21, 0.29, 0.27, 0.33]}, 'img1008876.jpg': {'Inference': [0.88, 0.3, 0.95, 0.34]}, 'img1008877.jpg': {'Inference': [0.87, 0.06, 0.92, 0.11]}, 'img1008880.jpg': {'Inference': [0.45, 0.4, 0.5, 0.44]}, 'img1008881.jpg': {'Inference': [0.49, 0.34, 0.52, 0.38]}, 'img1008883.jpg': {'Inference': [0.86, 0.36, 0.92, 0.4]}, 'img1008886.jpg': {'Inference': 0}, 'img1008887.jpg': {'Inference': [0.95, 0.08, 1.0, 0.15]}, 'img1008888.jpg': {'Inference': [0.33, 0.48, 0.39, 0.52]}, 'img1008889.jpg': {'Inference': [0.31, 0.34, 0.35, 0.37]}, 'img1008890.jpg': {'Inference': [0.49, 0.34, 0.51, 0.36]}, 'img1008891.jpg': {'Inference': [0.38, 0.42, 0.42, 0.45]}, 'img1008892.jpg': {'Inference': [0.48, 0.35, 0.51, 0.37]}, 'img1008893.jpg': {'Inference': [0.3, 0.42, 0.33, 0.45]}, 'img1008939.jpg': {'Inference': [0.57, 0.22, 0.61, 0.27]}, 'img1008940.jpg': {'Inference': [0.52, 0.47, 0.55, 0.5]}, 'img1008942.jpg': {'Inference': [0.39, 0.47, 0.43, 0.5]}, 'img1008943.jpg': {'Inference': [0.51, 0.02, 0.57, 0.08]}, 'img1008950.jpg': {'Inference': [0.42, 0.57, 0.46, 0.6]}, 'img1008951.jpg': {'Inference': [0.58, 0.52, 0.61, 0.55]}, 'img1008952.jpg': {'Inference': [0.51, 0.52, 0.55, 0.56]}, 'img1008953.jpg': {'Inference': [0.63, 0.5, 0.66, 0.53]}, 'img1008954.jpg': {'Inference': [0.66, 0.44, 0.69, 0.47]}, 'img1008955.jpg': {'Inference': [0.42, 0.52, 0.45, 0.55]}, 'img1008956.jpg': {'Inference': [0.45, 0.34, 0.48, 0.36]}, 'img1008957.jpg': {'Inference': [0.46, 0.4, 0.49, 0.43]}, 'img1008958.jpg': {'Inference': [0.59, 0.42, 0.61, 0.44]}, 'img1008959.jpg': {'Inference': [0.62, 0.46, 0.65, 0.49]}, 'img1008960.jpg': {'Inference': [0.65, 0.43, 0.69, 0.46]}, 'img1008961.jpg': {'Inference': [0.63, 0.41, 0.66, 0.44]}, 'img1008962.jpg': {'Inference': [0.46, 0.48, 0.5, 0.52]}, 'img1008963.jpg': {'Inference': [0.39, 0.44, 0.43, 0.47]}, 'img1008964.jpg': {'Inference': [0.61, 0.37, 0.66, 0.42]}, 'img1009166.jpg': {'Inference': [0.58, 0.48, 0.63, 0.52]}, 'img1009167.jpg': {'Inference': [480.0, 568.0, 512.0, 600.0]}, 'img1009327.jpg': {'Inference': [0.24, 0.3, 0.28, 0.33]}, 'img1009333.jpg': {'Inference': [0.75, 0.53, 0.79, 0.57]}, 'img1009504.jpg': {'Inference': [0.46, 0.37, 0.53, 0.43]}, 'img1009641.jpg': {'Inference': [0.67, 0.47, 0.7, 0.5]}, 'img1009667.jpg': {'Inference': [0.63, 0.35, 0.69, 0.4]}, 'img1009668.jpg': {'Inference': [0.51, 0.31, 0.59, 0.37]}, 'img1009669.jpg': {'Inference': [0.5, 0.2, 0.59, 0.3]}, 'img1009670.jpg': {'Inference': [704.0, 235.0, 745.0, 278.0]}, 'img1009671.jpg': {'Inference': [0.46, 0.17, 0.51, 0.22]}, 'img1009753.jpg': {'Inference': [0.65, 0.44, 0.69, 0.48]}, 'img1009754.jpg': {'Inference': [0.63, 0.26, 0.67, 0.31]}, 'img1009755.jpg': {'Inference': [0.57, 0.36, 0.6, 0.39]}, 'img1009834.jpg': {'Inference': [0.51, 0.53, 0.56, 0.57]}, 'img1009836.jpg': {'Inference': [0.15, 0.03, 0.2, 0.08]}, 'img1009935.jpg': {'Inference': [0.47, 0.08, 0.52, 0.13]}, 'img1009936.jpg': {'Inference': [568.0, 924.0, 666.0, 999.0]}, 'img1010076.jpg': {'Inference': [0.5, 0.08, 0.55, 0.14]}, 'img1048402.jpg': {'Inference': 0}, 'img1048403.jpg': {'Inference': 0}, 'img1048404.jpg': {'Inference': 0}, 'img1048405.jpg': {'Inference': 0}, 'img1048406.jpg': {'Inference': 0}, 'img1048407.jpg': {'Inference': 0}, 'img1048408.jpg': {'Inference': 0}, 'img1048409.jpg': {'Inference': 0}, 'img1048410.jpg': {'Inference': 0}, 'img1048411.jpg': {'Inference': 0}, 'img1048453.jpg': {'Inference': [805.0, 464.0, 835.0, 494.0]}, 'img1048454.jpg': {'Inference': 0}, 'img1048455.jpg': {'Inference': [0.79, 0.48, 0.83, 0.52]}, 'img1048456.jpg': {'Inference': [786.0, 485.0, 817.0, 518.0]}, 'img1048457.jpg': {'Inference': [778.0, 496.0, 808.0, 526.0]}, 'img1048458.jpg': {'Inference': [768.0, 505.0, 796.0, 535.0]}, 'img1048459.jpg': {'Inference': [0.75, 0.51, 0.78, 0.54]}, 'img1048460.jpg': {'Inference': [744.0, 525.0, 768.0, 552.0]}, 'img1048461.jpg': {'Inference': [726.0, 537.0, 750.0, 561.0]}, 'img1048462.jpg': {'Inference': [720.0, 539.0, 747.0, 566.0]}, 'img1048463.jpg': {'Inference': [714.0, 546.0, 735.0, 568.0]}, 'img1048464.jpg': {'Inference': [708.0, 546.0, 735.0, 573.0]}, 'img1049744.jpg': {'Inference': [0.7, 0.83, 0.73, 0.86]}, 'img1049745.jpg': {'Inference': [0.64, 0.81, 0.68, 0.84]}, 'img1049746.jpg': {'Inference': [562.0, 878.0, 584.0, 900.0]}, 'img1049747.jpg': {'Inference': [555.0, 882.0, 577.0, 905.0]}, 'img1049748.jpg': {'Inference': [500.0, 885.0, 535.0, 915.0]}, 'img1049749.jpg': {'Inference': [0.47, 0.85, 0.5, 0.88]}, 'img1049750.jpg': {'Inference': [0.41, 0.86, 0.45, 0.89]}}\n",
      "Images processed in 462.25820326805115 seconds\n"
     ]
    }
   ],
   "source": [
    "PROCESS_IMAGES = time.time()\n",
    "process_images(IMAGE_PATH)\n",
    "print(f\"Images processed in {time.time() - PROCESS_IMAGES} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621623fe",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "id": "a8266ee9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T11:09:04.081961Z",
     "start_time": "2024-09-16T11:09:04.076922Z"
    }
   },
   "source": [
    "def calculate_accuracy(json_path):\n",
    "\n",
    "    with open(json_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    total_images = 0\n",
    "    images_with_bounding_box = 0\n",
    "\n",
    "\n",
    "    for img_name, result in data.items():\n",
    "        total_images += 1\n",
    "\n",
    "        if isinstance(result, list) and len(result) == 4:\n",
    "            images_with_bounding_box += 1\n",
    "\n",
    "\n",
    "    accuracy = images_with_bounding_box / total_images if total_images > 0 else 0\n",
    "\n",
    "\n",
    "    print(f\"Total Images: {total_images}\")\n",
    "    print(f\"Images with Detections (Bounding Box): {images_with_bounding_box}\")\n",
    "    print(f\"Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "calculate_accuracy('output/inference_results.json')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images: 403\n",
      "Images with Detections (Bounding Box): 326\n",
      "Accuracy: 80.89%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8089330024813896"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "637fd862",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5f8076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare both JSON files and see how good the inse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
