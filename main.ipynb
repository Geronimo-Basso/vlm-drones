{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c76b170844c1ea2d",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aebc857ccabefdcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T18:49:27.252901Z",
     "start_time": "2024-09-12T18:49:23.590665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\r\n",
      "  Cloning https://github.com/huggingface/transformers to /private/var/folders/_3/b70qb3856jv2v4tk1htvvt1w0000gn/T/pip-req-build-mms3c4yp\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /private/var/folders/_3/b70qb3856jv2v4tk1htvvt1w0000gn/T/pip-req-build-mms3c4yp\r\n",
      "^C\r\n",
      "\u001B[31mERROR: Operation cancelled by user\u001B[0m\u001B[31m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6d064f254330843",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T18:49:27.805734Z",
     "start_time": "2024-09-12T18:49:27.255147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qwen-vl-utils in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (0.0.4)\r\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from qwen-vl-utils) (10.4.0)\r\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from qwen-vl-utils) (2.32.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from requests->qwen-vl-utils) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from requests->qwen-vl-utils) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from requests->qwen-vl-utils) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from requests->qwen-vl-utils) (2024.8.30)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install qwen-vl-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "473b2def78489f75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T18:49:28.327728Z",
     "start_time": "2024-09-12T18:49:27.807217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (0.19.1)\r\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from torchvision) (1.26.4)\r\n",
      "Requirement already satisfied: torch==2.4.1 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from torchvision) (2.4.1)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from torchvision) (10.4.0)\r\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from torch==2.4.1->torchvision) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from torch==2.4.1->torchvision) (4.11.0)\r\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from torch==2.4.1->torchvision) (1.13.2)\r\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from torch==2.4.1->torchvision) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from torch==2.4.1->torchvision) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from torch==2.4.1->torchvision) (2024.3.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from torch==2.4.1->torchvision) (72.1.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from jinja2->torch==2.4.1->torchvision) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from sympy->torch==2.4.1->torchvision) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "541953d9a385e1c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T18:49:28.847097Z",
     "start_time": "2024-09-12T18:49:28.329628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (0.34.2)\r\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from accelerate) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from accelerate) (24.1)\r\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from accelerate) (5.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from accelerate) (6.0.1)\r\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from accelerate) (2.4.1)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from accelerate) (0.24.6)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from accelerate) (0.4.4)\r\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.3.1)\r\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.11.0)\r\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (1.13.2)\r\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\r\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (72.1.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/vlm-drones/lib/python3.12/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T15:45:01.824243Z",
     "start_time": "2024-09-15T15:45:01.817508Z"
    }
   },
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "START = time.time()\n",
    "LOCAL_RUN = False"
   ],
   "id": "7698a201861b8546"
  },
  {
   "cell_type": "code",
   "id": "9f5edf966658b15e",
   "metadata": {},
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ae08d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_MODEL = time.time()\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-7B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "print(f\"Model loaded in {time.time() - LOAD_MODEL} seconds\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "LOAD_PROCESSOR = time.time()\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\")\n",
    "print(f\"Processor loaded in {time.time() - LOAD_PROCESSOR} seconds\")"
   ],
   "id": "a76d7f8f54abceae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def extract_coordinates(output_text):\n",
    "    coord_pattern = r'\\(([\\d\\.\\,\\s]+)\\)'\n",
    "    match = re.search(coord_pattern, output_text)\n",
    "    \n",
    "    if match:\n",
    "\n",
    "        coordinates = match.group(1).split(',')\n",
    "        coordinates = list(map(float, coordinates))\n",
    "        \n",
    "        if len(coordinates) == 4:\n",
    "            return coordinates\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ],
   "id": "458c95ebd07d0aa8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d6ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(data_directory):\n",
    "    prompt = \"Detect drones in the image. If a drone is detected, return only the bounding box coordinates normalized between 0 and 1, in the format (x, y, w, h), where (x, y) is the top-left corner of the bounding box relative to the image dimensions, and w and h are the width and height relative to the image dimensions. No other text or information; only the coordinates.\"\n",
    "    results_dict = {}\n",
    "    quantity = len(os.listdir(data_directory))\n",
    "\n",
    "    for filename in os.listdir(data_directory):\n",
    "        if filename.endswith('.jpg'):\n",
    "\n",
    "            image_path = os.path.join(data_directory, filename)\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"image\", \"image\": f\"file://{image_path}\"},\n",
    "                        {\"type\": \"text\", \"text\": prompt},\n",
    "                    ],\n",
    "                }\n",
    "            ]\n",
    "\n",
    "    \n",
    "\n",
    "            text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "            image_inputs, video_inputs = process_vision_info(messages)\n",
    "            inputs = processor(\n",
    "                text=[text],\n",
    "                images=image_inputs,\n",
    "                videos=video_inputs,\n",
    "                padding=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "\n",
    "            generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "            generated_ids_trimmed = [\n",
    "                out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "            ]\n",
    "            output_text = processor.batch_decode(\n",
    "                generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "            )[0]\n",
    "\n",
    "            print(f\"Pending to process {quantity -1}\")\n",
    "            \n",
    "            output_text_parse = extract_coordinates(output_text)\n",
    "\n",
    "            results_dict[filename] = {\n",
    "                \"Inference\": output_text_parse\n",
    "            }\n",
    "\n",
    "    output_path = os.path.join(data_directory, 'vlm-drones/output/inference_results.json')\n",
    "    with open(output_path, 'w') as json_file:\n",
    "        json.dump(results_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d81132",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESS_IMAGES = time.time()\n",
    "process_images('vlm-drones/images/')\n",
    "print(f\"Images processed in {time.time() - PROCESS_IMAGES} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
